{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-12T04:47:31.055109Z",
     "start_time": "2024-08-12T04:47:31.053618Z"
    }
   },
   "source": [
    ""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T04:47:32.194640Z",
     "start_time": "2024-08-12T04:47:31.133477Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from models.fcn.fcn import FCN\n",
    "from models.classifiers.linear import LinearClassifier\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "from utils.data import load_data, transfer_labels, normalize_per_series\n",
    "from utils.data import UCRDataset, fill_nan_value\n",
    "from utils.kfold import k_fold\n",
    "from utils.save_classification_results import save_cls_result\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import tqdm\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "from utils.evaluate import evaluate\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ],
   "id": "e3751ff634dd6448",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T04:47:32.197201Z",
     "start_time": "2024-08-12T04:47:32.195708Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "f32cad6c0c7c8548",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Build Dataset",
   "id": "5ae34221af42c22d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T04:47:32.215089Z",
     "start_time": "2024-08-12T04:47:32.197731Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_test_dataset, train_test_target, num_classes = load_data(data_root='data/UCR_TS_Archive_2015',  dataset='Adiac')\n",
    "train_test_target = transfer_labels(train_test_target)\n",
    "\n",
    "num_classes = num_classes\n",
    "seq_len = train_test_dataset.shape[1]\n",
    " "
   ],
   "id": "8c07f381fed82878",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T04:47:32.219915Z",
     "start_time": "2024-08-12T04:47:32.216490Z"
    }
   },
   "cell_type": "code",
   "source": "train_test_dataset",
   "id": "52357fe292e88129",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.598 , 1.5994, 1.5705, ..., 1.5642, 1.5709, 1.5929],\n",
       "       [1.7011, 1.6706, 1.6189, ..., 1.5197, 1.6025, 1.6702],\n",
       "       [1.7223, 1.6953, 1.6569, ..., 1.6418, 1.695 , 1.7085],\n",
       "       ...,\n",
       "       [1.652 , 1.6968, 1.7006, ..., 1.4993, 1.5557, 1.6204],\n",
       "       [1.3987, 1.2934, 1.1888, ..., 1.6363, 1.5626, 1.4605],\n",
       "       [1.7272, 1.7284, 1.6938, ..., 1.6273, 1.6753, 1.6989]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T04:47:32.221830Z",
     "start_time": "2024-08-12T04:47:32.220596Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "cadc286044320db6",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model",
   "id": "2727e379aaa6536f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T04:47:32.358548Z",
     "start_time": "2024-08-12T04:47:32.222435Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_fcn = FCN(input_size=1, num_classes=2)\n",
    "linear_classifier = LinearClassifier(128, 2)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "model_init_state = model_fcn.state_dict()\n",
    "classifier_init_state = linear_classifier.state_dict()\n",
    "\n",
    "optimizer = torch.optim.Adam([{'params': model_fcn.parameters()}, {'params': linear_classifier.parameters()}],\n",
    "                                     lr=0.001, weight_decay=0.0)\n",
    "\n",
    "train_test_dataset = normalize_per_series(train_test_dataset)\n"
   ],
   "id": "d4fcf9ec85451328",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T04:47:32.361692Z",
     "start_time": "2024-08-12T04:47:32.359181Z"
    }
   },
   "cell_type": "code",
   "source": "train_test_dataset",
   "id": "ead0912c46af7141",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.6025561, 1.6039602, 1.5749776, ..., 1.5686598, 1.5753788,\n",
       "        1.5974416],\n",
       "       [1.7059497, 1.6753628, 1.6235152, ..., 1.5240326, 1.6070685,\n",
       "        1.6749616],\n",
       "       [1.7272137, 1.7001365, 1.661627 , ..., 1.646484 , 1.6998358,\n",
       "        1.7133743],\n",
       "       ...,\n",
       "       [1.6567166, 1.7016445, 1.7054554, ..., 1.5035807, 1.5601417,\n",
       "        1.6250263],\n",
       "       [1.4026968, 1.2970963, 1.1921976, ..., 1.6409751, 1.5670648,\n",
       "        1.4646733],\n",
       "       [1.732125 , 1.7333285, 1.6986297, ..., 1.6319402, 1.6800771,\n",
       "        1.7037443]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T04:47:32.363515Z",
     "start_time": "2024-08-12T04:47:32.362229Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "29a789b3ca2f383",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Loading train and test dataset",
   "id": "f467a0786f8dc39"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T04:47:32.416271Z",
     "start_time": "2024-08-12T04:47:32.364108Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = 'mps'\n",
    "batch_size = 8\n",
    "train_set = UCRDataset(torch.from_numpy(train_test_dataset).to(device),\n",
    "                               torch.from_numpy(train_test_target).to(device).to(torch.int64))\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, num_workers=0)\n",
    "\n",
    "# Adiac dataset is univariate. meaning it has only one channel and 176 timesteps\n",
    "print(f\"Train loader shape: {train_loader.dataset.dataset.shape}\")\n"
   ],
   "id": "c379a8bef3e56852",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader shape: torch.Size([781, 1, 176])\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T04:47:32.419971Z",
     "start_time": "2024-08-12T04:47:32.418554Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "349ab11fa90e3871",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Pre-Training the model",
   "id": "10d772cc5e4dc540"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T04:48:00.262818Z",
     "start_time": "2024-08-12T04:47:32.420808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "last_loss = float('inf')\n",
    "stop_count = 0\n",
    "increase_count = 0\n",
    "\n",
    "min_loss = float('inf')\n",
    "min_epoch = 0\n",
    "model_to_save = None\n",
    "\n",
    "save_dir = \"models_archive/pre_trained\"\n",
    "pre_training_dataset = \"Adiac\"  # Dataset Name\n",
    "\n",
    "model_fcn.to(device)\n",
    "linear_classifier.to(device)\n",
    "\n",
    "num_steps = train_set.__len__() // batch_size\n",
    "for epoch in range(1, 101):\n",
    "    \n",
    "    if stop_count == 50 or increase_count == 50:\n",
    "        print(\"model convergent at epoch {}, early stopping.\".format(epoch))\n",
    "        break\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "    \n",
    "    model_fcn.train()\n",
    "    linear_classifier.train()\n",
    "    for batch_idx, (data, target) in tqdm.tqdm(enumerate(train_loader), total=len(train_loader), desc=\"Pre-training FCN\"):\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model_fcn(data)\n",
    "        predictions = linear_classifier(predictions)\n",
    "        \n",
    "        step_loss = loss(predictions, target)\n",
    "        step_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += step_loss.item()\n",
    "        epoch_accuracy += torch.sum(torch.argmax(predictions.data, axis=1) == target) / len(target)\n",
    "        \n",
    "    epoch_loss /= num_steps\n",
    "    if abs(epoch_loss - last_loss) <= 1e-4:\n",
    "        stop_count += 1\n",
    "    else:\n",
    "        stop_count = 0\n",
    "\n",
    "    if epoch_loss > last_loss:\n",
    "        increase_count += 1\n",
    "    else:\n",
    "        increase_count = 0\n",
    "        \n",
    "    last_loss = epoch_loss\n",
    "    if epoch_loss < min_loss:\n",
    "        min_loss = epoch_loss\n",
    "        min_epoch = epoch\n",
    "        model_to_save = model_fcn.state_dict()\n",
    "        classifier_to_save = linear_classifier.state_dict()\n",
    "\n",
    "    epoch_accuracy /= num_steps\n",
    "    if epoch % 100 == 0:\n",
    "        print(\"epoch : {}, loss : {}, accuracy : {}\".format(epoch, epoch_loss, epoch_accuracy))\n",
    "        torch.save(model_to_save, os.path.join(save_dir, pre_training_dataset, 'pretrain_weights.pt'))\n",
    "        torch.save(classifier_to_save, os.path.join(save_dir, pre_training_dataset, 'classifier_weights.pt'))\n",
    "\n",
    "print('{} finished pretrain, with min loss {} at epoch {}'.format(pre_training_dataset, min_loss, min_epoch))\n",
    "torch.save(model_to_save, os.path.join(save_dir, pre_training_dataset, 'pretrain_weights.pt'))\n"
   ],
   "id": "75577422fb92f3c9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pre-training FCN:   0%|          | 0/98 [00:00<?, ?it/s]/Users/neereshkumarperla/miniconda3/lib/python3.10/site-packages/torch/nn/modules/conv.py:306: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at /private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_5ae0635zuj/croot/pytorch-select_1700511177724/work/aten/src/ATen/native/Convolution.cpp:1009.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 124.42it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 206.65it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 209.12it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 212.49it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 212.14it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 212.18it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 213.70it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 210.25it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 212.09it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 211.85it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 213.07it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 204.64it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 210.72it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 208.99it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 212.62it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 210.47it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 214.28it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 212.56it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 212.63it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 210.64it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 213.20it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 213.31it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 206.03it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 216.05it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 213.97it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 214.55it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 214.16it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 216.45it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 216.45it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 211.48it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 212.71it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 213.68it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 213.69it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 203.96it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 213.57it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 211.63it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 213.20it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 213.64it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 212.49it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 213.02it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 212.85it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 214.86it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 212.43it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 209.77it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 206.40it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 213.18it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 212.15it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 211.46it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 211.15it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 210.76it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 208.88it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 212.08it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 210.09it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 211.49it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 201.52it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 202.72it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 211.53it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 210.84it/s]\n",
      "Pre-training FCN: 100%|██████████| 98/98 [00:00<00:00, 209.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model convergent at epoch 60, early stopping.\n",
      "Adiac finished pretrain, with min loss 0.017359792955757417 at epoch 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T04:48:00.265068Z",
     "start_time": "2024-08-12T04:48:00.263610Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d797836921f7f7fb",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Finetuning on another dataset",
   "id": "aa06e40db66c7973"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T04:48:00.376578Z",
     "start_time": "2024-08-12T04:48:00.265667Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Loading weights\n",
    "torch.load(f\"models_archive/pre_trained/{pre_training_dataset}/classifier_weights.pt\")\n"
   ],
   "id": "9fb4c9f01c05984e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('dense.weight',\n",
       "              tensor([[-1.0743e-01, -6.0665e-02,  5.1999e-05,  1.1033e-01, -6.8118e-02,\n",
       "                        1.3369e-01, -1.8848e-02,  1.3225e-01,  9.0464e-02,  1.3808e-01,\n",
       "                       -6.3941e-02,  9.6029e-02,  2.9341e-02, -9.8433e-02, -5.6932e-02,\n",
       "                       -4.4407e-02,  1.1042e-01, -1.3372e-01,  1.3426e-01, -1.2734e-01,\n",
       "                        1.0477e-01,  8.7777e-02,  1.2434e-01, -4.0225e-02, -8.2705e-02,\n",
       "                       -6.6935e-02,  1.3251e-01,  1.3236e-02,  1.6723e-02, -7.8169e-02,\n",
       "                        4.4514e-02, -3.6628e-02,  3.6761e-02,  8.1834e-02,  1.2099e-01,\n",
       "                        1.3229e-01, -1.1962e-01,  8.5638e-02,  1.1296e-01, -8.4369e-02,\n",
       "                        1.9186e-02, -6.2912e-02,  2.8851e-02,  8.5476e-02,  1.0799e-02,\n",
       "                       -1.1907e-01,  9.0666e-02,  4.3757e-02, -9.7290e-02,  1.3246e-01,\n",
       "                       -1.1541e-01, -6.1207e-02,  1.1963e-01, -7.2790e-02, -8.8357e-02,\n",
       "                        9.6742e-02,  2.5471e-02, -8.2464e-02, -5.2979e-02, -3.4118e-02,\n",
       "                        1.3023e-01, -1.1709e-01,  7.4864e-02,  7.5420e-02,  2.4419e-02,\n",
       "                        1.2451e-01, -1.0461e-01, -1.1058e-01,  9.3497e-02, -1.6424e-02,\n",
       "                       -9.3218e-02, -8.8847e-02,  1.0721e-01, -2.1164e-02,  1.6086e-02,\n",
       "                       -1.8819e-02, -9.9403e-02, -5.3087e-02,  1.2952e-01, -2.6987e-02,\n",
       "                        1.1242e-01,  9.5666e-02, -7.4264e-02,  1.3379e-01,  1.3681e-01,\n",
       "                       -4.8687e-02,  3.8024e-03,  9.5025e-02, -8.9347e-02, -9.5155e-02,\n",
       "                        9.7915e-03,  2.8693e-02, -4.9020e-02, -1.1346e-01, -1.0811e-01,\n",
       "                       -1.2444e-03, -9.9212e-02,  1.4321e-01,  1.0953e-01, -4.7896e-02,\n",
       "                        1.1394e-02, -5.8562e-02,  2.3294e-02, -3.5453e-02, -1.7253e-02,\n",
       "                       -1.2421e-01, -3.6553e-02, -1.2029e-01,  1.3242e-01, -3.9197e-02,\n",
       "                        6.0047e-02,  1.2879e-01,  9.7195e-02,  1.1981e-01,  1.0257e-01,\n",
       "                        1.3374e-01, -8.1500e-02, -7.1178e-02, -2.1963e-03,  2.6995e-02,\n",
       "                       -8.5079e-02,  1.1567e-01,  6.3182e-02,  1.0730e-01,  1.0529e-01,\n",
       "                       -3.9929e-02, -4.8601e-02, -7.8004e-03],\n",
       "                      [-4.4095e-02,  5.0510e-02,  7.9109e-02, -1.3627e-01,  6.6600e-02,\n",
       "                       -5.3009e-02,  9.4524e-02, -2.9889e-02, -2.4634e-02,  6.0026e-03,\n",
       "                        1.0552e-01, -1.8430e-02, -1.1659e-01,  1.8986e-02,  1.1279e-01,\n",
       "                        2.0430e-02, -7.0009e-02,  4.7363e-02, -1.1936e-01, -1.5990e-02,\n",
       "                       -1.0270e-02, -2.8618e-02, -1.2465e-01,  4.2248e-02, -2.0423e-02,\n",
       "                        1.0948e-01, -9.0098e-02,  9.4778e-02,  1.1416e-01,  2.5757e-02,\n",
       "                       -1.2269e-01,  6.9937e-02, -1.2985e-01, -1.2997e-01,  8.6814e-03,\n",
       "                       -4.0929e-02,  1.0342e-01, -2.9516e-02, -1.2941e-01,  1.0097e-01,\n",
       "                       -1.0523e-01,  8.9671e-02, -1.0402e-01, -2.7281e-02, -1.1287e-01,\n",
       "                        1.4317e-02, -1.2070e-01, -1.0615e-01, -3.7760e-03, -2.1241e-02,\n",
       "                       -9.3833e-03,  7.3959e-03, -3.3123e-02,  3.3834e-02, -8.8562e-03,\n",
       "                       -6.8124e-02,  1.2597e-01,  6.7828e-02,  2.3960e-02,  9.6158e-02,\n",
       "                       -1.2120e-01,  5.7002e-03, -7.8825e-02, -1.1963e-01,  1.1188e-01,\n",
       "                       -1.2944e-01,  4.3641e-02,  1.1078e-01, -9.2987e-02,  7.2687e-02,\n",
       "                        9.1054e-02,  5.6251e-02, -9.6642e-02,  9.9920e-02, -1.0899e-01,\n",
       "                        9.3102e-02,  8.5297e-02,  1.0806e-01, -1.1985e-01,  7.7440e-02,\n",
       "                       -4.0027e-02, -1.2948e-01,  4.7623e-02, -9.7458e-02, -8.3121e-02,\n",
       "                        9.0735e-02,  1.1914e-01, -1.1124e-01,  9.4359e-02,  1.7431e-02,\n",
       "                        9.7289e-02, -8.2744e-02,  1.1215e-01, -5.1081e-02,  7.1180e-02,\n",
       "                        6.7528e-02,  9.9804e-02, -1.3429e-01, -9.5417e-02,  7.4965e-02,\n",
       "                       -1.3877e-01,  7.7360e-02, -1.0741e-01,  8.9352e-02, -1.3510e-01,\n",
       "                        4.6639e-02,  3.9987e-02,  8.7455e-02, -3.8919e-02,  1.2171e-01,\n",
       "                       -1.0654e-01, -8.9135e-02, -1.0655e-01, -1.3519e-01, -1.9933e-02,\n",
       "                       -2.5543e-02,  1.4112e-02,  1.2185e-01,  8.6283e-02,  1.1858e-01,\n",
       "                        2.7986e-02, -4.2277e-02, -9.3437e-02, -3.5092e-02, -5.4884e-02,\n",
       "                        1.1511e-01,  1.1122e-01,  7.9756e-02]], device='mps:0')),\n",
       "             ('dense.bias', tensor([-0.0165,  0.0301], device='mps:0'))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Loading Target Dataset",
   "id": "1e83d717b454e1f7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T04:48:00.390306Z",
     "start_time": "2024-08-12T04:48:00.377342Z"
    }
   },
   "cell_type": "code",
   "source": [
    "finetuned_dataset = 'ArrowHead'\n",
    "train_test_dataset, train_test_target, num_classes = load_data(data_root='data/UCR_TS_Archive_2015', \n",
    "                                                               dataset=finetuned_dataset)\n",
    "train_test_target = transfer_labels(train_test_target)\n",
    " "
   ],
   "id": "73158f198d3c1806",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T04:48:00.395276Z",
     "start_time": "2024-08-12T04:48:00.390982Z"
    }
   },
   "cell_type": "code",
   "source": "train_datasets, train_targets, val_datasets, val_targets, test_datasets, test_targets = k_fold(train_test_dataset, train_test_target)\n",
   "id": "156451ee8261fd4e",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T04:48:41.025023Z",
     "start_time": "2024-08-12T04:48:00.396007Z"
    }
   },
   "cell_type": "code",
   "source": [
    "losses = []\n",
    "test_accuracies = []\n",
    "train_time = 0.0\n",
    "end_val_epochs = []\n",
    "\n",
    "for i, train_dataset in enumerate(train_datasets):\n",
    "    t = time.time()\n",
    "    model_fcn.load_state_dict(torch.load(os.path.join(save_dir, 'Adiac', 'pretrain_weights.pt')))\n",
    "    linear_classifier.load_state_dict(classifier_init_state)\n",
    "    print('{} fold start training and evaluate'.format(i))\n",
    "    max_accuracy = 0\n",
    "    \n",
    "    train_target = train_targets[i]\n",
    "    val_dataset = val_datasets[i]\n",
    "    val_target = val_targets[i]\n",
    "\n",
    "    test_dataset = test_datasets[i]\n",
    "    test_target = test_targets[i]\n",
    "    \n",
    "    train_dataset, val_dataset, test_dataset = fill_nan_value(train_dataset, val_dataset, test_dataset)\n",
    "    train_dataset = normalize_per_series(train_dataset)\n",
    "    val_dataset = normalize_per_series(val_dataset)\n",
    "    test_dataset = normalize_per_series(test_dataset)\n",
    "    \n",
    "    train_set = UCRDataset(torch.from_numpy(train_dataset).to(device), \n",
    "                           torch.from_numpy(train_target).to(device).to(torch.int64))\n",
    "    val_set = UCRDataset(torch.from_numpy(val_dataset).to(device),\n",
    "                         torch.from_numpy(val_target).to(device).to(torch.int64))\n",
    "    test_set = UCRDataset(torch.from_numpy(test_dataset).to(device),\n",
    "                          torch.from_numpy(test_target).to(device).to(torch.int64))\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, num_workers=0, drop_last=True)\n",
    "    val_loader = DataLoader(val_set, batch_size=batch_size, num_workers=0)\n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size, num_workers=0)\n",
    "    \n",
    "    train_loss = []\n",
    "    train_accuracy = []\n",
    "    num_steps = epoch // batch_size\n",
    "\n",
    "    last_loss = float('inf')\n",
    "    stop_count = 0\n",
    "    increase_count = 0\n",
    "\n",
    "    test_accuracy = 0\n",
    "    min_val_loss = float('inf')\n",
    "    end_val_epoch = 0\n",
    "    \n",
    "    num_steps = train_set.__len__() // batch_size\n",
    "    for epoch in range(1, 101):\n",
    "        if stop_count == 50 or increase_count == 50:\n",
    "            print('model convergent at epoch {}, early stopping'.format(epoch))\n",
    "            break\n",
    "\n",
    "        epoch_train_loss = 0\n",
    "        epoch_train_acc = 0\n",
    "        model_fcn.train()\n",
    "        linear_classifier.train()\n",
    "        for x, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            pred = model_fcn(x)\n",
    "            pred = linear_classifier(pred)\n",
    "\n",
    "            step_loss = loss(pred, y)\n",
    "            step_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_train_loss += step_loss.item()\n",
    "            epoch_train_acc += torch.sum(torch.argmax(pred.data, axis=1) == y) / len(y)\n",
    "\n",
    "        epoch_train_loss /= num_steps\n",
    "        epoch_train_acc /= num_steps\n",
    "\n",
    "        model_fcn.eval()\n",
    "        linear_classifier.eval()\n",
    "        val_loss, val_accu = evaluate(val_loader, model_fcn, linear_classifier, loss, device)\n",
    "        if min_val_loss > val_loss:\n",
    "            min_val_loss = val_loss\n",
    "            end_val_epoch = epoch\n",
    "            test_loss, test_accuracy = evaluate(test_loader, model_fcn, linear_classifier, loss, device)\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"epoch : {}, train loss: {} , train accuracy : {}, \\nval loss : {}, val accuracy : {}, \\ntest loss : {}, test accuracy : {}\".format(epoch, epoch_train_loss, epoch_train_acc, val_loss, val_accu, test_loss, test_accuracy))\n",
    "\n",
    "        if abs(last_loss - val_loss) <= 1e-4:\n",
    "            stop_count += 1\n",
    "        else:\n",
    "            stop_count = 0\n",
    "\n",
    "        if val_loss > last_loss:\n",
    "            increase_count += 1\n",
    "        else:\n",
    "            increase_count = 0\n",
    "\n",
    "        last_loss = val_loss\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    end_val_epochs.append(end_val_epoch)\n",
    "    t = time.time() - t\n",
    "    train_time += t\n",
    "\n",
    "    print('{} fold finish training'.format(i))\n",
    "\n",
    "test_accuracies = torch.Tensor(test_accuracies)\n",
    "end_val_epochs = np.array(end_val_epochs)\n",
    "\n",
    "save_cls_result(save_dir='results', save_csv_name='FCN', dataset_name=f'{pre_training_dataset}_{finetuned_dataset}',\n",
    "                test_accu=torch.mean(test_accuracies), test_std=torch.std(test_accuracies),\n",
    "                train_time=train_time / 5, end_val_epoch=np.mean(end_val_epochs))\n",
    "print('Done!')\n"
   ],
   "id": "233ffd587380e9aa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 fold start training and evaluate\n",
      "epoch : 100, train loss: 0.38766416609287263 , train accuracy : 0.6083333492279053, \n",
      "val loss : 0.04485278824965159, val accuracy : 0.5476190447807312, \n",
      "test loss : 0.03937501962794814, test accuracy : 0.6279069781303406\n",
      "0 fold finish training\n",
      "1 fold start training and evaluate\n",
      "epoch : 100, train loss: 0.38616437117258706 , train accuracy : 0.6000000238418579, \n",
      "val loss : 0.0371894363400548, val accuracy : 0.6511628031730652, \n",
      "test loss : 0.039125887410981317, test accuracy : 0.6428571343421936\n",
      "1 fold finish training\n",
      "2 fold start training and evaluate\n",
      "epoch : 100, train loss: 0.3683502991994222 , train accuracy : 0.6083333492279053, \n",
      "val loss : 0.05686238200165505, val accuracy : 0.39534884691238403, \n",
      "test loss : 0.04233402120215552, test accuracy : 0.5476190447807312\n",
      "2 fold finish training\n",
      "3 fold start training and evaluate\n",
      "epoch : 100, train loss: 0.4028823475042979 , train accuracy : 0.5583333373069763, \n",
      "val loss : 0.04579668405444123, val accuracy : 0.5348837375640869, \n",
      "test loss : 0.044520508675348194, test accuracy : 0.523809552192688\n",
      "3 fold finish training\n",
      "4 fold start training and evaluate\n",
      "epoch : 100, train loss: 0.37236410975456236 , train accuracy : 0.6083333492279053, \n",
      "val loss : 0.050702341074167295, val accuracy : 0.4883720874786377, \n",
      "test loss : 0.04277552735237848, test accuracy : 0.5714285969734192\n",
      "4 fold finish training\n",
      "Done!\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T04:48:41.026902Z",
     "start_time": "2024-08-12T04:48:41.025612Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "7969d4d8bda51524",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Results",
   "id": "4d6b5df559addd00"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T04:48:41.033668Z",
     "start_time": "2024-08-12T04:48:41.027610Z"
    }
   },
   "cell_type": "code",
   "source": "pd.read_csv('results/FCN_cls_result.csv')",
   "id": "a6557a791cc1914b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   id     dataset_name  test_accuracy  test_std  train_time  end_val_epoch  \\\n",
       "0   0  Adiac_ArrowHead         0.6112    0.0562      8.1199           97.2   \n",
       "1   1  Adiac_ArrowHead         0.5782    0.0260      7.8860           93.0   \n",
       "2   2  Adiac_ArrowHead         0.5827    0.0512      8.1239           85.8   \n",
       "\n",
       "   seeds  \n",
       "0     42  \n",
       "1     42  \n",
       "2     42  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_std</th>\n",
       "      <th>train_time</th>\n",
       "      <th>end_val_epoch</th>\n",
       "      <th>seeds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Adiac_ArrowHead</td>\n",
       "      <td>0.6112</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>8.1199</td>\n",
       "      <td>97.2</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Adiac_ArrowHead</td>\n",
       "      <td>0.5782</td>\n",
       "      <td>0.0260</td>\n",
       "      <td>7.8860</td>\n",
       "      <td>93.0</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Adiac_ArrowHead</td>\n",
       "      <td>0.5827</td>\n",
       "      <td>0.0512</td>\n",
       "      <td>8.1239</td>\n",
       "      <td>85.8</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T04:48:41.035529Z",
     "start_time": "2024-08-12T04:48:41.034383Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "3b05ac12d62e1dc6",
   "outputs": [],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
